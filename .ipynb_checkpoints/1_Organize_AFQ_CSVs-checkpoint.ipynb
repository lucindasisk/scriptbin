{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "from os import makedirs, getcwd\n",
    "from os.path import dirname, join\n",
    "today=str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EDIT THESE VARIABLES\n",
    "\n",
    "tp='TK3' # This is the timepoint for which you are running the script\n",
    "sunet = 'sisklm' # This is the sunet of the person who ran AFQ)\n",
    "newstem = '202-tmid' # This is the stem you want to use to identify the files this script will produce -- I.E. 'Tmid_AllSubs'\n",
    "stem='TK3_4.28.19' # This is the stem of the AFQ files you are organizing \n",
    "# For instance, if your AFQ output file is LS_AllSubs_TK1_Left_Arcuate.csv, the stem would be \"LS_AllSubs_TK1\"\n",
    "\n",
    "##### DO NOT EDIT VARIABLES PAST THIS POINT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/myelin/Dropbox/Github/ELS_TK3/matproc/AFQ_results'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oak paths - used to strip off path from variable name\n",
    "oakp1 = '/share/Oak/'+sunet+'/ELS_data/ELS_DTI_Analysis/ELS_{}/matproc/els'.format(tp)\n",
    "oakp2 = '-{}/dti60trilin/'.format(tp)\n",
    "\n",
    "# path=getcwd()\n",
    "# pdir=dirname(path)\n",
    "# home=join(pdir,'ELS_{}/matproc/AFQ_results'.format(tp))\n",
    "home='/Volumes/iang/ELS_data/ELS_DTI_Analysis/ELS_{}/matproc/AFQ_results'.format(tp)\n",
    "\n",
    "#Tracts from which we will be extracting\n",
    "tracts = ['Arcuate','Cingulum_Cingulate','Cingulum_Hippocampus', 'Corticospinal', 'IFOF',\n",
    "         'IFOF', 'ILF', 'SLF', 'Thalmic_Radiation', 'Uncinate']\n",
    "hemisphere = ['Left', 'Right']\n",
    "metrics = ['AD', 'FA', 'MD', 'RD']\n",
    "\n",
    "#Read in Age CSV\n",
    "age=pd.read_csv('/Volumes/iang/ELS_data/ELS_DTI_Analysis/DateAgeFiles/{}_Ages_Dates.csv'.format(tp),header=0).astype(str)\n",
    "age.rename(columns={'Date of Scan':'Date.of.Scan.{}'.format(tp), 'Age at Scan':'Age.at.Scan.{}'.format(tp)}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir exists for Arcuate\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for Cingulum_Cingulate\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for Cingulum_Hippocampus\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for Corticospinal\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for IFOF\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for IFOF\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for ILF\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for SLF\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for Thalmic_Radiation\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for Uncinate\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n"
     ]
    }
   ],
   "source": [
    "first_run = 'no'\n",
    "for tract in tracts:\n",
    "    try:\n",
    "        makedirs(home+'/'+tract)\n",
    "    except:\n",
    "        pass\n",
    "    for hemi in hemisphere:\n",
    "        for metric in metrics:\n",
    "            print('Cleaning data for {}_{}_{}_{}.csv'.format(stem,hemi,tract,metric))\n",
    "                df = pd.read_csv(home + '/{}_{}_{}_{}.csv'.format(stem,hemi,tract,metric), header = None)\n",
    "                df.iloc[:,0] = df.iloc[:,0].astype(str)\n",
    "                rng = range(1, len(list(df)))\n",
    "                new_cols = ['subject ID'] + ['{}.{}.{}.{}.node'.format(hemi,tract,metric,tp) + str(i) for i in rng] #+ ['expt_' + str(i) for i in rng]\n",
    "                df.columns = new_cols\n",
    "                df['subject ID']=df['subject ID'].str.replace(oakp1,'').str.replace('els','').str.replace(oakp2,'').str.replace('-{}'.format(tp),'').str.lstrip('0')\n",
    "                df2 = pd.merge(age, df, on='subject ID', how='right').sort_values(by='subject ID')\n",
    "                df2['{}.{}.{}.{}.mean'.format(hemi,tract,metric,tp)] = df2.iloc[:,3:103].mean(axis=1)\n",
    "                if first_run == 'yes':\n",
    "                    try:\n",
    "                        makedirs(home+'/'+tract+'/CLEAN_5.1.19')\n",
    "                    except:\n",
    "                       pass\n",
    "                    df2.to_csv(home + '/{}/CLEAN_5.1.19/ELS_{}_Cleaned_{}_{}_{}_2019-05-01.csv'.format(tract,tp,hemi,tract,metric), index=False)\n",
    "                elif first_run =='no':\n",
    "                    df2.to_csv(home + '/{}/ELS_{}_{}_Cleaned_{}_{}_{}_{}.csv'.format(tract,tp,newstem,hemi,tract,metric,today), index=False)\n",
    "                    print('New data saved to ELS_{}_{}_Cleaned_{}_{}_{}_{}.csv'.format(tract,tp,newstem,hemi,tract,metric,today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir exists for Callosum_Forceps_Minor\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "Dir exists for Callosum_Forceps_Major\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n",
      "CLEAN folder exists\n"
     ]
    }
   ],
   "source": [
    "tract2 = ['Callosum_Forceps_Minor', 'Callosum_Forceps_Major']\n",
    "for tract in tract2:\n",
    "    try:\n",
    "        makedirs(home+'/'+tract)\n",
    "    except:\n",
    "        print('Dir exists for {}'.format(tract))\n",
    "    for metric in metrics:\n",
    "            df = pd.read_csv(home + '/{}_{}_{}.csv'.format(stem,tract,metric), header = None)\n",
    "            df.iloc[:,0] = df.iloc[:,0].astype(str)\n",
    "            rng = range(1, len(list(df)))\n",
    "            new_cols = ['subject ID'] + ['{}.{}.{}.node'.format(tract,metric,tp) + str(i) for i in rng] #+ ['expt_' + str(i) for i in rng]\n",
    "            df.columns = new_cols\n",
    "            df['subject ID']=df['subject ID'].str.replace(oakp1,'').str.replace('els','').str.replace(oakp2,'').str.replace('-{}'.format(tp),'').str.lstrip('0')\n",
    "            df2 = pd.merge(age, df, on='subject ID', how='right').sort_values(by='subject ID')\n",
    "            df2['{}.{}.{}.mean'.format(tract,metric,tp)] = df2.iloc[:,3:103].mean(axis=1)\n",
    "            if first_run =='yes':\n",
    "                try:\n",
    "                    makedirs(home+'/'+tract+'/CLEAN_5.1.19')\n",
    "                except:\n",
    "                    print('CLEAN folder exists')\n",
    "                df2.to_csv(home + '/{}/CLEAN_5.1.19/ELS_{}_Cleaned_{}_{}_2019-05-01.csv'.format(tract,tp,tract,metric), index=False)\n",
    "            elif first_run =='no':\n",
    "                df2.to_csv(home + '/{}/ELS_{}_{}_Cleaned_{}_{}_{}.csv'.format(tract,tp,newstem,tract,metric,today), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Troubleshooting section - ignore\n",
    "\n",
    "# tract='Arcuate'\n",
    "# hemi='Left'\n",
    "# metric='FA'\n",
    "\n",
    "# df = pd.read_csv(home + '/{}_{}_{}_{}.csv'.format(stem,hemi,tract,metric), header = None)\n",
    "# df.iloc[:,0] = df.iloc[:,0].astype(str)\n",
    "# rng = range(1, len(list(df)))\n",
    "# new_cols = ['subject ID'] + ['{}.{}.{}.{}.node'.format(hemi,tract,metric,tp) + str(i) for i in rng] #+ ['expt_' + str(i) for i in rng]\n",
    "# df.columns = new_cols\n",
    "# df['subject ID']=df['subject ID'].str.replace(oakp1,'').str.replace(oakp2,'').str.lstrip('0')\n",
    "# df2 = pd.merge(age, df, on='subject ID', how='right').sort_values(by='subject ID')\n",
    "# df2['{}.{}.{}.{}.mean'.format(hemi,tract,metric,tp)] = df2.iloc[:,3:103].mean(axis=1)\n",
    "# #df2.to_csv(home + '/{}/ELS_{}_{}_Cleaned_{}_{}_{}_{}.csv'.format(tract,incsubs,tp,hemi,tract,metric,today), index=False)\n",
    "# age.iloc[:,0] = age.iloc[:,0].astype(str)\n",
    "# age.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
